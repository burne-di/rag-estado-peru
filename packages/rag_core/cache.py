"""
Sistema de cach√© para respuestas del LLM.
Evita llamadas repetidas a la API para preguntas similares.
"""
import hashlib
import json
import re
import threading
import time
import unicodedata
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Optional


@dataclass
class CacheEntry:
    """Entrada en el cach√©"""
    question_hash: str
    question: str
    answer: dict
    timestamp: float
    hits: int = 0


class ResponseCache:
    """
    Cach√© de respuestas LLM con persistencia en disco.

    Features:
    - Hash de preguntas normalizadas para matching exacto
    - TTL (Time To Live) configurable
    - Persistencia en JSON para sobrevivir reinicios
    - Thread-safe para uso concurrente
    - Estad√≠sticas de uso
    """

    def __init__(
        self,
        cache_dir: str = "./data/cache",
        ttl_hours: int = 24,
        max_entries: int = 1000
    ):
        """
        Args:
            cache_dir: Directorio donde guardar el cach√©
            ttl_hours: Tiempo de vida de las entradas en horas
            max_entries: N√∫mero m√°ximo de entradas en cach√©
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / "response_cache.json"

        self.ttl_seconds = ttl_hours * 3600
        self.max_entries = max_entries

        self._cache: dict[str, CacheEntry] = {}
        self._lock = threading.Lock()
        self._stats = {"hits": 0, "misses": 0, "saves": 0}

        # Cargar cach√© existente
        self._load_cache()

    def _normalize_question(self, question: str) -> str:
        """Normaliza la pregunta para mejor matching"""
        # Lowercase, remover espacios extra, remover puntuaci√≥n
        text = question.lower().strip()
        # Remover acentos
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        # Remover puntuaci√≥n
        text = re.sub(r'[^\w\s]', '', text)
        # Normalizar espacios
        text = re.sub(r'\s+', ' ', text)

        return text

    def _hash_question(self, question: str) -> str:
        """Genera hash √∫nico para una pregunta normalizada"""
        normalized = self._normalize_question(question)
        return hashlib.sha256(normalized.encode()).hexdigest()[:16]

    def get(self, question: str) -> Optional[dict]:
        """
        Busca una respuesta en cach√©.

        Args:
            question: Pregunta del usuario

        Returns:
            Respuesta cacheada o None si no existe/expir√≥
        """
        question_hash = self._hash_question(question)

        with self._lock:
            if question_hash not in self._cache:
                self._stats["misses"] += 1
                return None

            entry = self._cache[question_hash]

            # Verificar TTL
            if time.time() - entry.timestamp > self.ttl_seconds:
                del self._cache[question_hash]
                self._stats["misses"] += 1
                return None

            # Cache hit!
            entry.hits += 1
            self._stats["hits"] += 1

            print(f"üì¶ Cache HIT para: '{question[:50]}...' (hits: {entry.hits})")

            return entry.answer

    def set(self, question: str, answer: dict) -> None:
        """
        Guarda una respuesta en cach√©.

        Args:
            question: Pregunta del usuario
            answer: Respuesta generada
        """
        question_hash = self._hash_question(question)

        with self._lock:
            # Limpiar entradas antiguas si excedemos el l√≠mite
            if len(self._cache) >= self.max_entries:
                self._evict_oldest()

            self._cache[question_hash] = CacheEntry(
                question_hash=question_hash,
                question=question,
                answer=answer,
                timestamp=time.time(),
                hits=0
            )

            self._stats["saves"] += 1
            self._save_cache()

            print(f"üíæ Cache SAVE para: '{question[:50]}...'")

    def _evict_oldest(self) -> None:
        """Elimina las entradas m√°s antiguas (LRU simple)"""
        if not self._cache:
            return

        # Ordenar por timestamp y eliminar el 20% m√°s antiguo
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: x[1].timestamp
        )

        entries_to_remove = max(1, len(sorted_entries) // 5)

        for key, _ in sorted_entries[:entries_to_remove]:
            del self._cache[key]

        print(f"üóëÔ∏è Cache eviction: eliminadas {entries_to_remove} entradas antiguas")

    def _load_cache(self) -> None:
        """Carga el cach√© desde disco"""
        if not self.cache_file.exists():
            return

        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            current_time = time.time()
            loaded = 0

            for entry_data in data.get("entries", []):
                # Verificar TTL al cargar
                if current_time - entry_data["timestamp"] <= self.ttl_seconds:
                    entry = CacheEntry(**entry_data)
                    self._cache[entry.question_hash] = entry
                    loaded += 1

            print(f"üìÇ Cache cargado: {loaded} entradas v√°lidas")

        except (json.JSONDecodeError, KeyError) as e:
            print(f"‚ö†Ô∏è Error cargando cach√©: {e}")
            self._cache = {}

    def _save_cache(self) -> None:
        """Guarda el cach√© a disco"""
        try:
            data = {
                "version": 1,
                "saved_at": time.time(),
                "entries": [asdict(entry) for entry in self._cache.values()]
            }

            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

        except IOError as e:
            print(f"‚ö†Ô∏è Error guardando cach√©: {e}")

    def get_stats(self) -> dict:
        """Retorna estad√≠sticas del cach√©"""
        with self._lock:
            total_requests = self._stats["hits"] + self._stats["misses"]
            hit_rate = (
                self._stats["hits"] / total_requests * 100
                if total_requests > 0 else 0
            )

            return {
                "total_entries": len(self._cache),
                "hits": self._stats["hits"],
                "misses": self._stats["misses"],
                "saves": self._stats["saves"],
                "hit_rate_percent": round(hit_rate, 2),
                "estimated_savings": f"{self._stats['hits']} llamadas a API evitadas"
            }

    def clear(self) -> None:
        """Limpia todo el cach√©"""
        with self._lock:
            self._cache = {}
            self._stats = {"hits": 0, "misses": 0, "saves": 0}

            if self.cache_file.exists():
                self.cache_file.unlink()

            print("üßπ Cache limpiado completamente")


# Singleton global
_cache_instance: Optional[ResponseCache] = None


def get_cache() -> ResponseCache:
    """Obtiene la instancia singleton del cach√©"""
    global _cache_instance
    if _cache_instance is None:
        _cache_instance = ResponseCache()
    return _cache_instance
