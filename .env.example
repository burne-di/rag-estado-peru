# LLM Providers (configura al menos uno)
# Provider a usar: "auto" (detecta disponible), "groq", o "gemini"
LLM_PROVIDER=auto

# Groq API (recomendado - más rápido)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=openai/gpt-oss-120b

# Google Gemini API
GOOGLE_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# Embedding Model (local, no requiere API key)
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# ChromaDB
CHROMA_PERSIST_DIR=./data/chroma

# RAG Parameters
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5

# Hybrid Search
HYBRID_SEARCH=true
VECTOR_WEIGHT=0.7
KEYWORD_WEIGHT=0.3

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
